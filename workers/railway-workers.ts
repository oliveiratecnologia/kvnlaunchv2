#!/usr/bin/env node
// workers/railway-workers.ts
// Workers BullMQ para Railway - Arquitetura HÃ­brida

import * as dotenv from 'dotenv';
import { resolve } from 'path';

// Carregar variÃ¡veis de ambiente
dotenv.config({ path: resolve(process.cwd(), '.env.local') });

import {
  createContentWorker,
  createPDFWorker,
  createUploadWorker,
  getQueueMetrics,
  cleanupOldJobs
} from '../lib/bullmq-upstash-config';
import {
  upstashRedisConnection,
  verificarConexaoUpstash
} from '../lib/redis-config-upstash';
import { generateEbookStructure, generateEbookPDF } from '../lib/pdf-generator';
import { supabase } from '../lib/supabaseClient';

// Cores para logs
const colors = {
  reset: '\x1b[0m',
  bright: '\x1b[1m',
  red: '\x1b[31m',
  green: '\x1b[32m',
  yellow: '\x1b[33m',
  blue: '\x1b[34m',
  cyan: '\x1b[36m',
};

function log(message: string, color: string = colors.reset) {
  const timestamp = new Date().toISOString();
  console.log(`${color}[${timestamp}] ${message}${colors.reset}`);
}

function logSuccess(message: string) {
  log(`âœ… ${message}`, colors.green);
}

function logError(message: string) {
  log(`âŒ ${message}`, colors.red);
}

function logInfo(message: string) {
  log(`â„¹ï¸  ${message}`, colors.blue);
}

function logWarning(message: string) {
  log(`âš ï¸  ${message}`, colors.yellow);
}

// Processador de conteÃºdo (OpenAI)
async function processContentJob(job: any) {
  logInfo(`Processando job de conteÃºdo: ${job.id}`);

  try {
    const { ebookData, userId, requestId } = job.data;

    logInfo(`Gerando estrutura do ebook: ${ebookData.titulo}`);

    // Usar a funÃ§Ã£o real de geraÃ§Ã£o de estrutura
    const ebookDataFormatted = {
      nome: ebookData.titulo,
      descricao: ebookData.detalhesAdicionais || `Ebook sobre ${ebookData.categoria}`,
      nicho: ebookData.categoria,
      subnicho: ebookData.categoria,
      persona: {
        nome: 'Leitor Interessado',
        idade: '25-45',
        interesses: [ebookData.categoria]
      }
    };

    const estrutura = await generateEbookStructure(ebookDataFormatted);

    // Calcular metadata
    const totalPalavras = estrutura.capitulos.reduce((total, cap) => {
      return total + cap.conteudo.length / 5; // AproximaÃ§Ã£o: 5 chars = 1 palavra
    }, 0);

    const metadata = {
      totalPalavras: Math.round(totalPalavras),
      tempoEstimadoLeitura: Math.ceil(totalPalavras / 200) // 200 palavras por minuto
    };

    logSuccess(`ConteÃºdo gerado para ${userId}: ${estrutura.capitulos.length} capÃ­tulos, ${metadata.totalPalavras} palavras`);

    return { estrutura, metadata };
  } catch (error) {
    logError(`Erro no processamento de conteÃºdo: ${error}`);
    throw error;
  }
}

// Processador de PDF (Puppeteer)
async function processPDFJob(job: any) {
  logInfo(`Processando job de PDF: ${job.id}`);

  try {
    const { estrutura, userId, requestId } = job.data;

    logInfo(`Gerando PDF para: ${estrutura.titulo}`);

    // Usar a funÃ§Ã£o real de geraÃ§Ã£o de PDF
    const pdfBuffer = await generateEbookPDF(estrutura);

    // Calcular nÃºmero aproximado de pÃ¡ginas (baseado no tamanho do conteÃºdo)
    const totalConteudo = estrutura.capitulos.reduce((total, cap) => {
      return total + cap.conteudo.length;
    }, 0);

    // AproximaÃ§Ã£o: 2500 caracteres por pÃ¡gina A4
    const paginasEstimadas = Math.max(1, Math.ceil(totalConteudo / 2500));

    const resultado = {
      pdfBuffer,
      tamanhoArquivo: pdfBuffer.length,
      paginasTotais: paginasEstimadas
    };

    logSuccess(`PDF gerado para ${userId}: ${(resultado.tamanhoArquivo / 1024 / 1024).toFixed(2)} MB, ~${resultado.paginasTotais} pÃ¡ginas`);

    return resultado;
  } catch (error) {
    logError(`Erro na geraÃ§Ã£o de PDF: ${error}`);
    throw error;
  }
}

// Processador de upload (Supabase)
async function processUploadJob(job: any) {
  logInfo(`Processando job de upload: ${job.id}`);

  try {
    const { pdfBuffer, nomeArquivo, userId, requestId, metadata } = job.data;

    logInfo(`Fazendo upload para Supabase: ${nomeArquivo}`);

    // Gerar caminho Ãºnico para o arquivo
    const timestamp = Date.now();
    const fileName = nomeArquivo || `ebook_${requestId}_${timestamp}.pdf`;
    const filePath = `ebooks/${userId}/${fileName}`;

    // Upload real para Supabase Storage
    const { data: uploadData, error: uploadError } = await supabase.storage
      .from('ebooks')
      .upload(filePath, pdfBuffer, {
        contentType: 'application/pdf',
        cacheControl: '3600',
        upsert: false // NÃ£o sobrescrever arquivos existentes
      });

    if (uploadError) {
      logError(`Erro no upload Supabase: ${uploadError.message}`);
      throw new Error(`Erro ao fazer upload: ${uploadError.message}`);
    }

    // Obter URL pÃºblica do arquivo
    const { data: urlData } = supabase.storage
      .from('ebooks')
      .getPublicUrl(filePath);

    const resultado = {
      urlPublica: urlData.publicUrl,
      nomeArquivo: fileName,
      tamanhoArquivo: pdfBuffer.length,
      uploadedAt: new Date().toISOString(),
      filePath: filePath,
      metadata: metadata || {}
    };

    logSuccess(`Upload concluÃ­do para ${userId}: ${fileName} (${(resultado.tamanhoArquivo / 1024 / 1024).toFixed(2)} MB)`);

    return resultado;
  } catch (error) {
    logError(`Erro no upload: ${error}`);
    throw error;
  }
}

// Health check endpoint
async function createHealthCheckServer() {
  const express = require('express');
  const app = express();
  const port = process.env.PORT || 3001;

  // Middleware bÃ¡sico
  app.use(express.json());
  
  app.get('/health', async (req: any, res: any) => {
    try {
      // Verificar conexÃ£o Redis
      const redisStatus = await verificarConexaoUpstash();
      
      // Obter mÃ©tricas das filas
      const metrics = await getQueueMetrics();
      
      const healthStatus = {
        status: redisStatus.connected ? 'healthy' : 'unhealthy',
        timestamp: new Date().toISOString(),
        redis: {
          connected: redisStatus.connected,
          latency: redisStatus.latency
        },
        queues: metrics,
        workers: {
          content: 'running',
          pdf: 'running',
          upload: 'running'
        }
      };
      
      res.status(redisStatus.connected ? 200 : 503).json(healthStatus);
    } catch (error) {
      res.status(503).json({
        status: 'unhealthy',
        error: error instanceof Error ? error.message : 'Unknown error',
        timestamp: new Date().toISOString()
      });
    }
  });
  
  app.listen(port, () => {
    logInfo(`Health check server rodando na porta ${port}`);
  });
}

// FunÃ§Ã£o principal
async function startWorkers() {
  logInfo('ðŸš€ Iniciando Workers BullMQ - Railway Hybrid Architecture');
  
  try {
    // Verificar conexÃ£o Redis
    logInfo('Verificando conexÃ£o com Upstash Redis...');
    const redisStatus = await verificarConexaoUpstash();
    
    if (!redisStatus.connected) {
      throw new Error(`Falha na conexÃ£o Redis: ${redisStatus.error}`);
    }
    
    logSuccess(`Redis conectado - LatÃªncia: ${redisStatus.latency}ms`);
    
    // Criar workers
    logInfo('Criando workers BullMQ...');
    
    const contentWorker = createContentWorker(processContentJob);
    const pdfWorker = createPDFWorker(processPDFJob);
    const uploadWorker = createUploadWorker(processUploadJob);
    
    // Event listeners para monitoramento e fluxo em cadeia
    contentWorker.on('completed', async (job, result) => {
      logSuccess(`Job de conteÃºdo completo: ${job.id}`);

      try {
        // Automaticamente criar job de PDF apÃ³s conteÃºdo
        const { pdfQueue } = await import('../lib/bullmq-upstash-config');

        const pdfJobData = {
          ...result,
          userId: job.data.userId,
          requestId: job.data.requestId
        };

        const pdfJob = await pdfQueue.add('generate-pdf', pdfJobData, {
          jobId: `pdf-${job.data.requestId}`,
          priority: 5
        });

        logInfo(`Job de PDF criado automaticamente: ${pdfJob.id}`);
      } catch (error) {
        logError(`Erro ao criar job de PDF: ${error}`);
      }
    });

    contentWorker.on('failed', (job, err) => {
      logError(`Job de conteÃºdo falhou: ${job?.id} - ${err.message}`);
    });
    
    pdfWorker.on('completed', async (job, result) => {
      logSuccess(`Job de PDF completo: ${job.id}`);

      try {
        // Automaticamente criar job de upload apÃ³s PDF
        const { uploadQueue } = await import('../lib/bullmq-upstash-config');

        const uploadJobData = {
          pdfBuffer: result.pdfBuffer,
          nomeArquivo: `${job.data.estrutura.titulo.replace(/[^a-zA-Z0-9]/g, '_')}.pdf`,
          userId: job.data.userId,
          requestId: job.data.requestId,
          metadata: {
            tamanhoArquivo: result.tamanhoArquivo,
            paginasTotais: result.paginasTotais,
            titulo: job.data.estrutura.titulo
          }
        };

        const uploadJob = await uploadQueue.add('upload-pdf', uploadJobData, {
          jobId: `upload-${job.data.requestId}`,
          priority: 1
        });

        logInfo(`Job de upload criado automaticamente: ${uploadJob.id}`);
      } catch (error) {
        logError(`Erro ao criar job de upload: ${error}`);
      }
    });

    pdfWorker.on('failed', (job, err) => {
      logError(`Job de PDF falhou: ${job?.id} - ${err.message}`);
    });
    
    uploadWorker.on('completed', (job) => {
      logSuccess(`Job de upload completo: ${job.id}`);
    });
    
    uploadWorker.on('failed', (job, err) => {
      logError(`Job de upload falhou: ${job?.id} - ${err.message}`);
    });
    
    logSuccess('Workers BullMQ iniciados com sucesso!');
    
    // Iniciar servidor de health check
    await createHealthCheckServer();
    
    // Limpeza automÃ¡tica a cada 30 minutos
    setInterval(async () => {
      try {
        await cleanupOldJobs();
        logInfo('Limpeza automÃ¡tica de jobs antigos executada');
      } catch (error) {
        logWarning(`Erro na limpeza automÃ¡tica: ${error}`);
      }
    }, 30 * 60 * 1000);
    
    // Log de mÃ©tricas a cada 5 minutos
    setInterval(async () => {
      try {
        const metrics = await getQueueMetrics();
        logInfo('ðŸ“Š MÃ©tricas das filas:');
        Object.entries(metrics).forEach(([nome, stats]) => {
          logInfo(`   ${nome}: waiting=${stats.waiting}, active=${stats.active}, completed=${stats.completed}, failed=${stats.failed}`);
        });
      } catch (error) {
        logWarning(`Erro ao obter mÃ©tricas: ${error}`);
      }
    }, 5 * 60 * 1000);
    
    logInfo('ðŸŽ¯ Workers prontos para processar jobs!');
    
  } catch (error) {
    logError(`Erro fatal ao iniciar workers: ${error}`);
    process.exit(1);
  }
}

// Graceful shutdown
process.on('SIGTERM', async () => {
  logInfo('ðŸ›‘ Recebido SIGTERM, encerrando workers...');
  await upstashRedisConnection.disconnect();
  process.exit(0);
});

process.on('SIGINT', async () => {
  logInfo('ðŸ›‘ Recebido SIGINT, encerrando workers...');
  await upstashRedisConnection.disconnect();
  process.exit(0);
});

// Iniciar workers
if (require.main === module) {
  startWorkers().catch((error) => {
    logError(`Erro fatal: ${error}`);
    process.exit(1);
  });
}

export { startWorkers };
